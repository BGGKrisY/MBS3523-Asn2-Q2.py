import cv2
import serial
import time
import numpy as np
confThreshold=0.6
ser = serial.Serial('COM3',baudrate=9600,timeout=1) # check the COM port that your Arduino Uno is connected to
time.sleep(0.5)
pos = 90 # initial value for the servo
classesFile='coco80.names'
classes=[]
cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)
with open(classesFile, 'r') as f:
    classes = f.read().splitlines()
    print(classes)
    print(len(classes))

net = cv2.dnn.readNetFromDarknet('yolov3-320.cfg','yolov3-320.weights')
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)


ser = serial.Serial('COM7',baudrate=9600,timeout=1)
time.sleep(2)
a = 90


while True:




    success, img = cam.read()
    height, width, ch = img.shape

    blob = cv2.dnn.blobFromImage(img, 1 / 255, (320, 320), (0, 0, 0), swapRB=True, crop=False)
    net.setInput(blob)

    layerNames = net.getLayerNames()
    print(layerNames)

    output_layers_names = net.getUnconnectedOutLayersNames()
    print(output_layers_names)

    LayerOutputs = net.forward(output_layers_names)
    print(len(LayerOutputs))


    bboxes = []  # array for all bounding boxes of detected classes
    confidences = []  # array for all confidence values of matching detected classes
    class_ids = []  # array for all class IDs of matching detected classes

    for output in LayerOutputs:
        for detection in output:
            scores = detection[5:]  # omit the first 5 values
            class_id = np.argmax(
                scores)  # find the highest score ID out of 80 values which has the highest confidence value
            confidence = scores[class_id]
            if confidence > confThreshold:
                center_x = int(detection[0] * width)  # YOLO predicts centers of image
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                bboxes.append([x, y, w, h])
                confidences.append((float(confidence)))
                class_ids.append(class_id)
                # cv2.rectangle(img, (x, y), (x + w, y + h), (255,0,0), 2)

    # print(len(bboxes))
    indexes = cv2.dnn.NMSBoxes(bboxes, confidences, confThreshold, 0.4)  # Non-maximum suppresion
    # print(indexes)
    # print(indexes.flatten())

    font = cv2.FONT_HERSHEY_PLAIN
    colors = np.random.uniform(0, 255, size=(len(bboxes), 3))

    if len(indexes) > 0:
        for i in indexes.flatten():
            x, y, w, h = bboxes[i]
            label = str(classes[class_ids[i]])
            confidence = str(round(confidences[i], 2))
            color = colors[i]
            if label == 'mouse':
                # cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 3)
                errorPan = (x + w/2) - 640/2
                print('errorPan', errorPan)
                # print(type(errorPan))
                if abs(errorPan) > 20:
                    pos = pos - errorPan/40
                    print(type(pos))
                if pos > 120:
                    pos = 120
                    print("Out of range")
                if pos < 70:
                    pos = 70
                    print("out of range")
                servoPos = str(pos) + '\r'
                ser.write(servoPos.encode('utf-8'))
                print('servoPos = ', servoPos)
                # print(type(pos))
                time.sleep(0.1)
                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)
                cv2.putText(img, label + " " + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)


    cv2.imshow('Image', img)
    # key = cv2.waitKey(1)
    # if key == 27:
    #     break
    if cv2.waitKey(1) & 0xff == 27:
        break

ser.close()
cam.release()
cv2.destroyAllWindows()
